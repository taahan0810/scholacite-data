Understanding context in machine translation has been a pivotal concern as it significantly influences the translation quality, especially when it comes to discourse phenomena such as anaphora, deixis, and lexical cohesion. A growing body of literature has begun to address these challenges. For instance, a study by [1] highlights the necessity of incorporating cross-sentence dependencies into Statistical Machine Translation to capture pronominal anaphora effectively. This finding is echoed by [3], who critically assess existing context-aware models and point out their inconsistent performance across various languages and phenomena. Further, the work presented in [6] underscores the potential of extended context in preventing errors and improving translation coherence for neural machine translation models. Moreover, [7] examines the pitfalls of machine translation due to the absence of context beyond the single-sentence level, accentuating the need for context-aware systems. Lastly, [8] offers a critical analysis of context-aware translation models, shedding light on their frequent failures to effectively utilize contextual information, a crucial insight for the current work-in-progress.

Evaluating these context-aware systems is another important aspect of the discourse, and several studies have been devoted to this theme. [2] introduces a comprehensive dataset and evaluation measure specifically tailored for pronoun translationâ€”a crucial discourse phenomenon. Building on this, [4] presents a test suite focused on pronoun translation and demonstrates the efficacy of context-aware models on this test set. Similarly, [5] provides a human study to evaluate neural machine translation models on their handling of discourse phenomena using specially designed test sets. The paper by [7] also plays a part in this evaluation discourse by identifying specific sources of inconsistencies in document-level translations and proposing a model that advances the field in these areas.

Lastly, the translation of pronominal anaphora is a niche but critical area within discourse phenomena translation. The paper by [1] offers insights into the translation of pronominal anaphora in statistical machine translation, relevant to the broader research focus. [2] furthers this by proposing a methodology to evaluate the translation of pronominal anaphora, which is vital for assessing the performance of machine translation systems. Additionally, [6] delves into the use of context in neural machine translation with a special emphasis on pronominal anaphora, perfectly aligning with the objectives of our work-in-progress.

Each of these studies contributes valuable insights to the field and, collectively, they help situate our work-in-progress within the larger academic conversation on context-aware machine translation. Our research aims to push the boundaries of this conversation by introducing the Multilingual Discourse-Aware (MUDA) benchmark, which targets a broader range of discourse phenomena, and by systematically identifying instances where context is paramount for accurate translation. Through this, we endeavor to address the gaps highlighted by the current literature and provide a more nuanced understanding of the nuances involved in context-aware machine translation.
