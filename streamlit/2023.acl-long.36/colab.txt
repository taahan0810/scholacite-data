Context Awareness in Machine Translation
Recent advancements in machine translation (MT) have emphasized the importance of context awareness, especially for addressing complex discourse phenomena such as pronoun translation, deixis, and lexical cohesion. Studies have shown that both statistical [1] and neural [6] translation models benefit from incorporating cross-sentence context, particularly in translating pronouns, where traditional sentence-by-sentence translation systems falter due to the absence of contextual dependencies. However, despite these advancements, effective incorporation of contextual information remains a challenge. The creation of custom datasets and evaluation measures [2], [4], [5] has facilitated a deeper understanding of context handling in MT, yet a comprehensive benchmark for systematically assessing a broader range of discourse phenomena has been elusive.

Discourse Phenomena in Machine Translation
The translation of pronominal anaphora and broader discourse issues like deixis and cohesion [3], [7], [8] underscores the necessity for wider context beyond individual sentences. While [1] and [6] demonstrate the integration of cross-sentence context to improve anaphora resolution, the translation of other discourse elements requires further exploration. The introduction of benchmark datasets [3], [4] aims to track improvements across various discourse phenomena, revealing that existing context-aware models do not consistently enhance discourse-related translations across languages. This inconsistency suggests a gap in the current methodologies for context incorporation [8].

Evaluating Context Handling and Benchmarking Efforts
Efforts to evaluate context handling in MT have been varied, with [2], [4], [5] contributing evaluation measures and test suites specifically designed for pronoun translation. These tools have been instrumental in highlighting the shortcomings of conventional automatic evaluation measures in capturing the nuances of discourse translation. Furthermore, [3] and [7] present new challenges in achieving translation improvements for deixis, ellipsis, and lexical cohesion, suggesting that while progress has been made, significant hurdles remain. The proposed MUDA benchmark aims to fill these gaps by offering a systematic approach to identifying and evaluating context-dependent discourse phenomena.

