Data-to-Text and Text-to-Data Generation. In the realm of converting structured data into coherent text, and vice versa, several methodologies and their respective challenges have been explored. A novel framework for semi-automatically creating training datasets for data-to-text generation is introduced by [1], delineating an approach that is particularly relevant to our goal of improving data-to-text generation. Likewise, the WebNLG Challenge posed by [2] and [3] invites exploration into generating text from RDF data, a concept closely aligned with our research aims. The creation of datasets tailored for open-domain structured data record to text generation is of significant relevance, as evidenced by [4], which presents the DART dataset, and [5], which introduces the ToTTo dataset for table-to-text generation. These developments are indicative of the advancements in the domain, as is the large-scale WikiTableT dataset [6] for generating Wikipedia article sections, which underscores the importance of comprehensive datasets in this field. The methodologies of table parsing via pre-training, an approach presented by [7], alongside the pretraining using tables [8], and the robust transformer modeling approach for table-text encoding [9], further contribute to the field by offering new perspectives on dealing with structured data. The unsupervised graph-to-text and text-to-graph generation method, CycleGT, advocated by [20], alongside a few-shot approach for table-to-text generation [15], and an any-shot data-to-text generation approach [13], all enrich the conversation by offering solutions for generating text with limited data resources, which is particularly germane to the research being conducted.

Fact Verification and Error Detection. The trustworthiness of generated text is paramount, particularly in relation to the factual content it conveys. The introduction of the TabFact dataset [10] marks a significant advancement in the effort to verify facts based on semi-structured data, which serves as a valuable resource for our research. Additionally, the development of DepChecker [11], which utilizes structured knowledge and dependency trees to fact-check machine-generated text, aligns with our imperative to enhance the accuracy of generated text.

Unsupervised and Few-Shot Learning. The unsupervised and few-shot learning paradigms provide a foundation for the cycle training approach we adopt. The cycle-consistent adversarial networks for image-to-image translation, discussed by [18], and the cycle consistency loss used to train ConvNets in [19] both underscore the utility of cycle consistency in unsupervised learning. Furthermore, the methodologies proposed in [21] for unsupervised textual transfer, and in [22] for unsupervised named entity recognition, exemplify the application of cycle training in a variety of contexts. The unsupervised approach to machine translation using only monolingual corpora [23], and the bidirectional keyword-question rewriting framework [24], expand upon the utility of unsupervised methodologies. The ASDOT approach [13], alongside the few-shot learning capabilities of large language models [14] and the few-shot table-to-text generation framework [15], highlight the potential of applying cycle training in low-resource scenarios.

Evaluation Metrics. The evaluation of models and techniques is facilitated by a range of metrics, among which the Bleu method [16] stands out for its language-independent and cost-effective assessment of machine translation, showing a high correlation with human evaluation. Complementing this, METEOR [17] offers a refined approach to machine translation evaluation, which could be valuable for assessing the performance of cycle training methods.

Applications in Online Shopping and Named Entity Recognition. Practical applications of text generation and data extraction in the online shopping and named entity recognition domains offer insights that are vital to our research. For example, understanding the key attributes for online product comparison [12] aids in generating descriptive text from product data. HCPC [25] tackles the task of generating comparative text for products, ensuring factual consistency, a concern that closely mirrors our research objectives. Additionally, the challenges highlighted in MultiCoNER [26], focusing on the recognition of complex named entities, resonate with the challenges of extracting structured data from text, further emphasizing the practical implications of our work.

In summary, across all these groupings, the cited works collectively provide a deep and varied insight into the challenges and solutions related to data-to-text generation, fact verification, unsupervised learning, evaluation methodologies, and the application of these technologies in real-world scenarios. These studies form a substantial underpinning for our work on faithful low-resource data-to-text generation using cycle training.
