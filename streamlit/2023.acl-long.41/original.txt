Humor. [1] and [2] highlight three “great families” of theories of the roots of humor: 1) hostility, claims of superiority over someone or something ([3]; [4]); 2) release of a constraint ([5]; [6]; [7]) and 3) incongruity, (sometimes “incongruity-resolution”; [8]) the introduction (and subsequent resolution) of generally incompatible contexts ([9]; [10]). [11] note that most New Yorker caption contest cartoons involve incongruous situations.

NLP + The Caption Contest. [12], [11], and [13] analyze 5, 16, and 50 New Yorker Caption Contests, respectively. Best-performing features for identifying the funniest among a set of caption choices include: perplexity, match to image setting and uncanniness description, readability, proper nouns ([11]), overlap with WordNet’s ([14]) “person” and “relative” synsets, lexical centrality among submissions ([13], inspired by [15]), and sentiment (both papers). Our “location” and “uncanny description” annotations are direct analogs of the “context” and “anomaly” tags of [11], and our data incorporates that generously released by the previous researchers. Our extensions are (a) the addition of two novel tasks; (b) using new data/resources/models to curate ranking pairs (see §2); and (c) evaluating two distinct audience preferences: New Yorker editors vs. “the crowd”. Appendix H highlights efforts beyond the scope of peer reviewed AI venues, e.g., blog posts.

Measuring preferences over captions. While humor is ultimately subjective, work on the contest has studied modeling average preferences of raters. [16] design quality ranking algorithms for the caption contest, framed as identifying the best “arm” in a multi-armed bandit setting; their crowdsourcing system NEXT ([17]) is used by The New Yorker. It does not directly use the content of the cartoons/contests. The result is [18]’s continuously updated corpus, from which we draw some of our data.

Multimodal and computational humor. [19] explore humor recognition in images, and [20]; [21]; [22]; [23] explore laughter prediction in TED-talks/sitcoms. [24]; [25] study political cartoons. [26] recently proposed a version of NLI for figurative language, which can be humorous. Some work has tried to detect whether a sentence is humorous or not ([27]; [28]). More difficult to evaluate ([29]) are setups where the goal is to automatically generate humorous content in various contexts ([30]; [31]; [32], [33]; [34]; [35]; [36]; [37]; [38]); a survey is provided by [39].

Explaining humor. In the taxonomy of [40], joke explanations are most related to proximal mechanisms: “This type of explanation attempts to provide the mechanism behind the predicted label, i.e., how to infer the label from the text”, or efficient cause a la Aristotle ([41]). [42] undertake a qualitative exploration of (non-visual) joke explanations.
